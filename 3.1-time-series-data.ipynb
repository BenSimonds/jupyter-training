{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Time series data viz\n",
    "\n",
    "One of the things that pandas is really great for working with is **time series** data. This is data for which the index (or at least one level in the index) is composed of datetime values denoting when the data is from.\n",
    "\n",
    "Time series data is abundant:\n",
    " - Stock market prices.\n",
    " - Data from sensors, IoT devices\n",
    " - Event streams from applications and services.\n",
    " - KPIs and performance data\n",
    " \n",
    " In pandas, we have a variety of tools for manipulating time series data, structured around having a pandas series or dataframe of data with a datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our Tesla share price data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'data/tsla_share_price.csv',\n",
    "    index_col='Date', # We tell pandas to use Date as the index\n",
    "    parse_dates=True, # We can tell pandas to try and automatically parse dates in index. In this case it does a good job\n",
    "    dayfirst=False, # Let pandas know our csv has an American (MM/DD) date format not a european one\n",
    ")\n",
    "\n",
    "# we can check out our index to see that pandas has interpreted it correctly.\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "First thing to notice is that pandas (with the help of matplotlib) does a good job of plotting time series data and adding ticks at sensible points on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger figure to plot to.\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df['Close'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "Pandas also has some nice tools for aggregating data over time, for examle calculating some monthly statistics from our daily data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we take our data and calulate the min, max, mean and standard deviation of the price each month.\n",
    "\n",
    "\n",
    "monthly_df = (\n",
    "    df.resample(\"1M\")                     # This creates a resampler object very like the gropuby object we created in the data transformation notebook.\n",
    "    ['Close']                             # We select close price from the dataframe.\n",
    "    .agg([\"min\",\"max\",\"mean\",\"std\"])      # Here we tell the resampler for close price to calculate a number of different summary satstics.\n",
    ")\n",
    "\n",
    "# If we look at this data, you'll see we now have one row per month.\n",
    "display(monthly_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot this data to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll construct a more elaborate plot here with two subplots.\n",
    "fix, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    sharex=True,\n",
    "    figsize=(16,16)\n",
    ")\n",
    "\n",
    "# Plot the mean value and the difference between the min and max on one subplot.\n",
    "axes[0].plot(\n",
    "    monthly_df.index,\n",
    "    monthly_df['mean'], \n",
    "    label=\"Mean Closing Price\"\n",
    ")\n",
    "axes[0].fill_between(\n",
    "    monthly_df.index,\n",
    "    monthly_df['min'], \n",
    "    monthly_df['max'], \n",
    "    alpha=0.2, \n",
    "    label=\"Closing Price Range - Min to Max\"\n",
    ")\n",
    "\n",
    "# Set a title for the subplot\n",
    "axes[0].set_title('Tesla Closing Price')\n",
    "\n",
    "# Add a legend using the labels we used for plotting\n",
    "axes[0].legend()\n",
    "\n",
    "# plot the standard deviation on another since the scale is different.\n",
    "axes[1].plot(\n",
    "    monthly_df.index, monthly_df['std'], label='Standard Deviation in Closing Price'\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "axes[1].set_title(\"Closing Price - Standard Deviation\")\n",
    "\n",
    "# show our plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "Load the example sales data from `data/sample-sales-data.csv`.\n",
    "- use `ORDERNUMBER` as the index.\n",
    "- parse `ORDERDATE` as a date (in American format). Hint: You can give the `parse_dates` column a list of columns with datetime data in them to try and parse them all.\n",
    "- filter out *Cancelled*, *On Hold* or *Disputed* orders with the `STATUS` column\n",
    "- create a summary with daily sales volumes by country with `pivot_table()`, use order date for the index, and country for the columns. Fill any nulls with zeroes.\n",
    "- resample the daily summary with `resample()` to calulate quarterly sales volumes for each country\n",
    "- add a column to the quartely summary for the total sales in all regions.\n",
    "- plot the total sales for all regions along with the sales for the UK as a line chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out cancelled, on hold and disputed orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily summary by country\n",
    "# Hint: use the pivot_table() method on our dataframe.\n",
    "daily_sales =  # << Add your code here\n",
    "\n",
    "\n",
    "# Remember to fill the nulls with zeroes.\n",
    "\n",
    "# View the result\n",
    "daily_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to quarterly sales. Hint use 'Q' to resample to quarterly frequency.\n",
    "quarterly_sales =  # << Add your code here\n",
    "\n",
    "\n",
    "# View the result\n",
    "quarterly_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for total sales\n",
    "quarterly_sales['Total'] = # << Add your code here\n",
    "quarterly_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our data\n",
    "\n",
    "# I've set a figure up for you.\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "# Fill in the '__''s below.\n",
    "ax.plot(__, __, label=\"UK\")\n",
    "ax.plot(__, __, label=\"Total Sales\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
